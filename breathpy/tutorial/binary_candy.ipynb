{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This tutorial demonstrates the binary analysis workflow of `BreathPy`.\n",
    "Initially sample data (MCC-IMS measurements of breath after consuming either `menthol` or `citrus` candy, see material section of https://www.mdpi.com/2218-1989/10/10/393 for more information) is downloaded and split into a training and test fraction - the test samples will later serve to validate the created random forest classifier. The samples are normalized and denoised. Afterwards, several peak-detection methods are applied including the `VisualnowLayer` contained in the sample data. Subsequently peaks are aligned using the `ProbeClustering` approach and the features are reduced using `RemovePercentageFeatures` - which limits the reported features to the ones present in at least `percentage_threshold` of the minority class - in this case `citrus`. \n",
    "Features are then weighted using the `PerformanceMeasure`s `RANDOM_FOREST_CLASSIFICATION` and `FDR_CORRECTED_P_VALUE` - leaving 10 features each. \n",
    "Two decision trees and a `RandomForestClassifier` are trained. They serve as visual interpretation of the classifcation strategy based on each `PerformanceMeasure`.\n",
    "After training, the `RandomForestClassifier` is used to predict the class labels of the test samples.\n",
    "Finally, plots are created and saved in the `results/plots/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imports\n",
    "from urllib.request import urlretrieve\n",
    "from shutil import move as file_move\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from breathpy.generate_sample_data import generate_train_test_sets, generate_train_test_set_helper\n",
    "from breathpy.model.BreathCore import (MccImsAnalysis, MccImsMeasurement, PredictionModel,\n",
    "                              construct_default_parameters,\n",
    "                              construct_default_processing_evaluation_steps,\n",
    "                              construct_custom_processing_evaluation_dict)\n",
    "from breathpy.model.ProcessingMethods import FeatureReductionMethod, PerformanceMeasure, GCMSPeakDetectionMethod, GCMSAlignmentMethod\n",
    "from breathpy.tools.tools import get_peax_binary_path\n",
    "\n",
    "from breathpy.view.BreathVisualizations import ClusterPlot, HeatmapPlot, RocCurvePlot, BoxPlot, TreePlot, TimeSeriesPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sample data and split into train and test fraction\n",
    "\n",
    "url = 'https://github.com/philmaweb/BreathAnalysis.github.io/raw/master/data/full_candy.zip'\n",
    "zip_dst = Path(\"data/full_candy.zip\")\n",
    "dst_dir = Path(\"data/full_candy/\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "urlretrieve(url, zip_dst)\n",
    "\n",
    "# unzip archive into data subdirectory\n",
    "with ZipFile(zip_dst, \"r\") as archive_handle:\n",
    "    archive_handle.extractall(Path(dst_dir))\n",
    "\n",
    "raw_dir = dst_dir\n",
    "target_dir = Path(\"data/\")\n",
    "\n",
    "# split into train and test fraction - use 1/3 of samples for validation\n",
    "generate_train_test_sets(dir_full_set=raw_dir, root_target_dir=target_dir, cross_val_num=3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we simplify and go step-by-step through the methods called by `breathpy.model.CoreTest.run_start_to_end_pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define default parameters and train / test directory\n",
    "folder_name = file_prefix = 'train_full_candy'\n",
    "\n",
    "plot_parameters, file_parameters = construct_default_parameters(file_prefix, folder_name, make_plots=True)\n",
    "\n",
    "# create default parameters for preprocessing and evaluation\n",
    "preprocessing_steps, evaluation_params_dict = construct_default_processing_evaluation_steps()\n",
    "\n",
    "# define directory for training and test set\n",
    "train_dir = Path(\"data/train_full_candy/\")\n",
    "test_dir = Path(\"data/test_full_candy/\")\n",
    "\n",
    "# get class label dict file from training set\n",
    "train_class_label_dict_fn = MccImsAnalysis.guess_class_label_extension(train_dir)\n",
    "\n",
    "# read in raw mcc-ims measurements of training set - based on class_label_dict\n",
    "train_measurements = [MccImsMeasurement(fn) for fn in train_dir.glob(\"*ims.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup analysis - need to get path of peax binary and get the visualnowlayer filename\n",
    "peax_binary_path = get_peax_binary_path()\n",
    "visualnow_layer_path = [filename for filename in train_dir.glob(\"*layer*\") if\n",
    "                        (str.endswith(str(filename), \"layer.csv\") or str.endswith(str(filename), \"layer.xls\"))][0]\n",
    "\n",
    "# create output directory\n",
    "if not Path(file_parameters['out_dir']).exists():\n",
    "    Path(file_parameters['out_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create analysis\n",
    "ims_analysis = MccImsAnalysis(\n",
    "    train_measurements, preprocessing_steps, outfile_names=[], performance_measure_parameters=evaluation_params_dict,\n",
    "    class_label_file=train_class_label_dict_fn, dir_level=file_parameters['dir_level'],\n",
    "    dataset_name=folder_name, visualnow_layer_file=visualnow_layer_path,\n",
    "    peax_binary_path=peax_binary_path)\n",
    "\n",
    "# run normalization, denoising and peak_detection for measurements using 6 cores\n",
    "# for peak_detection we run [PEAX, WATERSHED, VISUALNOWLAYER, TOPHAT] methods defined in preprocessing_steps\n",
    "# if one want to change default parameters, pass updated parameters for preprocessing_parameters\n",
    "ims_analysis.preprocess_multicore(num_cores=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and show a preprocessed measurement\n",
    "test_measurement = ims_analysis.measurements[0]\n",
    "HeatmapPlot.FastIntensityMatrix(test_measurement, plot_parameters=plot_parameters, title=str(test_measurement))\n",
    "\n",
    "Image(Path(\"results/plots/heatmaps/fast_train_full_candy_intentsity_plot_BD18_1408280834_ims.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align peak detection results\n",
    "ims_analysis.align_peaks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize\n",
    "* show average chromatogram for each candy type - after normalization and denoising\n",
    "* show clusters for each peak detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = ClusterPlot.ClusterBasic(ims_analysis, plot_parameters=plot_parameters)\n",
    "overlays = ClusterPlot.OverlayClasswiseAlignment(ims_analysis, plot_parameters=plot_parameters)\n",
    "\n",
    "# get paths of the images\n",
    "cluster_fn = Path(clusters[2][-1])\n",
    "overlay_fn_citrus =Path(\"results/plots/overlay/\")/overlays[2][-1]\n",
    "overlay_fn_menthol =Path(\"results/plots/overlay/\")/overlays[-2][-1]\n",
    "\n",
    "# display images for the TOPHAT method\n",
    "images = [cluster_fn, overlay_fn_citrus, overlay_fn_menthol]\n",
    "\n",
    "for fn in images:\n",
    "    display(Image(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply feature reduction\n",
    "ims_analysis.reduce_features(ims_analysis.AVAILABLE_FEATURE_REDUCTION_METHODS)\n",
    "# evaluate model performance using 3-fold cross-validation\n",
    "ims_analysis.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export preprocessed files, peak detection results and feature_matrixes to csv into results directory\n",
    "print(file_parameters['out_dir'])\n",
    "\n",
    "# export preprocessed files, peak detection results and feature_matrixes to csv into results directory\n",
    "ims_analysis.export_results_to_csv(file_parameters['out_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the analysis:\n",
    "* show estimated model performance - ROC curve\n",
    "* show best features superimposed for each candy type\n",
    "* plot boxplot and time-series plot for each feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plots = RocCurvePlot.ROCCurve(ims_analysis.analysis_result, plot_parameters=plot_parameters)\n",
    "box_plots = BoxPlot.BoxPlotBestFeature(ims_analysis.analysis_result, plot_parameters=plot_parameters)\n",
    "\n",
    "try:\n",
    "    dt_plots = TreePlot.DecisionTrees(ims_analysis.analysis_result, plot_parameters=plot_parameters, limit_to_peak_detection_method_name=\"TOPHAT\")\n",
    "except FileNotFoundError as e:\n",
    "    # might not both be installe - need system executable and python library\n",
    "    print(\"Probably graphviz is not installed - install via `conda install graphviz python-graphviz`\")\n",
    "    raise(e)\n",
    "\n",
    "ts_plots = TimeSeriesPlot.TimeSeriesFromAnalysis(ims_analysis, plot_parameters=plot_parameters, limit_to_pdmn=['TOPHAT'], limit_to_features=['Peak_0178','Peak_0231'])\n",
    "\n",
    "roc_fn = roc_plots[2][-1]\n",
    "box_plot_fn = box_plots[0][-1]\n",
    "if dt_plots:\n",
    "    dt_fn = Path(dt_plots[1][-1][-1])\n",
    "\n",
    "ts_fn0 = ts_plots[1][0]\n",
    "ts_fn1 = ts_plots[1][1]\n",
    "    \n",
    "# display images for the TOPHAT method\n",
    "images = [roc_fn, box_plot_fn, dt_fn, ts_fn0, ts_fn1]\n",
    "\n",
    "for fn in images:\n",
    "    display(Image(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "# export prediction model and import from pickle\n",
    "predictor_path = Path(file_parameters['out_dir'])/\"predictors.sav\"\n",
    "ims_analysis.analysis_result.export_prediction_models(path_to_save=predictor_path)\n",
    "predictors = joblib.load(predictor_path)\n",
    "\n",
    "predictionModel = PredictionModel(\n",
    "        preprocessing_params={s:{} for s in preprocessing_steps},\n",
    "        evaluation_params=ims_analysis.performance_measure_parameter_dict,\n",
    "        scipy_predictor_by_pdm=predictors,\n",
    "        feature_names_by_pdm=ims_analysis.analysis_result.feature_names_by_pdm,\n",
    "        peax_binary_path=peax_binary_path,\n",
    "        visualnow_layer_file=visualnow_layer_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  preparation - replace train_ with test_\n",
    "#  otherwise can't find measurements - as the class labels don't match the measurement names\n",
    "file_parameters['folder_path'] = file_parameters['folder_path'].replace(\"train_\", \"test_\")\n",
    "test_dir = file_parameters['folder_path']\n",
    "\n",
    "test_result_dir = file_parameters['out_dir'].replace(\"train_\", \"test_\")\n",
    "\n",
    "test_measurements_fns = sorted(Path(test_dir).glob(\"*ims.csv\"))\n",
    "test_measurements = [MccImsMeasurement(fn) for fn in test_measurements_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict - and run full preprocessing and alignment on test_measurements\n",
    "prediction = predictionModel.predict(test_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_dict_fn = MccImsAnalysis.guess_class_label_extension(test_dir)\n",
    "test_labels_dict = MccImsAnalysis.parse_class_labels(test_labels_dict_fn)\n",
    "class_labels = np.unique([m.class_label for m in ims_analysis.measurements])\n",
    "test_measurements_names = [path.name for path in test_measurements_fns]\n",
    "for pdm, prediction_index in prediction.items():\n",
    "    predicted_labels = {test_name: class_labels[p] for p, test_name in zip(prediction_index, test_measurements_names)}\n",
    "    correct = dict()\n",
    "    false = dict()\n",
    "    for fn, predicted_label in predicted_labels.items():\n",
    "        if predicted_label == test_labels_dict[fn]:\n",
    "            correct[fn] = predicted_label\n",
    "        else:\n",
    "            false[fn] = predicted_label\n",
    "\n",
    "    print(f\"resulting_labels for {pdm.name} are: {predicted_labels}\")\n",
    "    print(f\"Falsely classified: {false}\\n\")\n",
    "    print(f\"That's {len(correct.keys())} correct vs {len(false.keys())} false\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
